# VQA æ¼”ç¤ºä»£ç ä¿®å¤ç‰ˆæœ¬

ä»¥ä¸‹æ˜¯ä¿®å¤åçš„å®Œæ•´ `vqa_demo_simple.py` ä»£ç ï¼Œä¸“æ³¨äºåŠŸèƒ½å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

```python
#!/usr/bin/env python3
"""
ä½¿ç”¨ Qibo è‡ªåŠ¨å¾®åˆ†åç«¯è¿›è¡Œ VQA ç®—æ³•æ¼”ç¤ºï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Qibo çš„è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½å®ç°å˜åˆ†é‡å­ç®—æ³• (VQA)ã€‚
é€šè¿‡ä¼˜åŒ–é‡å­ç”µè·¯å‚æ•°ï¼Œä½¿è¾“å‡ºçŠ¶æ€å°½å¯èƒ½æ¥è¿‘ç›®æ ‡çŠ¶æ€ï¼ˆå‡åŒ€å åŠ æ€ï¼‰ã€‚

ä¿®å¤å†…å®¹ï¼š
1. ç»Ÿä¸€å¯¼å…¥è¯­å¥ï¼Œè§£å†³å¯¼å…¥ä¸ä¸€è‡´é—®é¢˜
2. æ·»åŠ åç«¯ç®¡ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œé˜²æ­¢å…¨å±€çŠ¶æ€æ±¡æŸ“
3. æ ‡å‡†åŒ–å‚æ•°åˆå§‹åŒ–å’Œç”µè·¯åˆ›å»º
4. æ”¹è¿›é”™è¯¯å¤„ç†å’Œèµ„æºç®¡ç†
5. ä¿®å¤æ€§èƒ½æ¯”è¾ƒå‡½æ•°çš„åç«¯è®¾ç½®é—®é¢˜

ä½œè€…ï¼šåŸºäº auto_diff.ipynb æ–‡ä»¶å†…å®¹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
"""

import numpy as np
import matplotlib.pyplot as plt
import warnings
import os
import time
from contextlib import contextmanager

# ç¡®ä¿ qibo ç›¸å…³å¯¼å…¥æ­£ç¡®
import qibo
from qibo import Circuit, gates, set_backend
from qibo.quantum_info import infidelity

warnings.filterwarnings('ignore')

@contextmanager
def backend_context(backend_name, platform=None):
    """å®‰å…¨åˆ‡æ¢åç«¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    original_backend = qibo.get_backend()
    try:
        set_backend(backend=backend_name, platform=platform)
        yield qibo.get_backend()
    finally:
        # ç¡®ä¿æ¢å¤åŸå§‹åç«¯
        set_backend(original_backend.name)

def create_variational_circuit(nqubits, params):
    """åˆ›å»ºæ ‡å‡†åŒ–çš„å˜åˆ†é‡å­ç”µè·¯"""
    circuit = Circuit(nqubits)
    if nqubits >= 2:
        circuit.add(gates.RX(0, params[0]))
        circuit.add(gates.RY(1, params[1]))
    return circuit

def create_target_state(backend_framework, nqubits=2):
    """åˆ›å»ºæ ‡å‡†åŒ–çš„ç›®æ ‡çŠ¶æ€ï¼ˆå‡åŒ€å åŠ æ€ï¼‰"""
    dim = 2 ** nqubits
    if backend_framework == "tensorflow":
        import tensorflow as tf
        return tf.ones(dim, dtype=tf.complex128) / np.sqrt(dim)
    elif backend_framework == "pytorch":
        import torch
        return torch.ones(dim, dtype=torch.complex128) / np.sqrt(dim)
    else:
        return np.ones(dim, dtype=np.complex128) / np.sqrt(dim)

def initialize_parameters(framework, nparams=2):
    """æ ‡å‡†åŒ–å‚æ•°åˆå§‹åŒ–"""
    if framework == "tensorflow":
        import tensorflow as tf
        return tf.Variable(
            tf.random.uniform((nparams,), dtype=tf.float64, minval=0, maxval=2*np.pi)
        )
    elif framework == "pytorch":
        import torch
        return torch.rand(nparams, dtype=torch.float64, requires_grad=True)
    else:
        return np.random.uniform(0, 2*np.pi, nparams)

def train_vqa(backend_name, platform, nepochs=1000, learning_rate=0.01):
    """æ ‡å‡†åŒ–çš„VQAè®­ç»ƒå‡½æ•°"""
    try:
        with backend_context(backend_name, platform) as backend:
            # è·å–æ¡†æ¶ç‰¹å®šçš„æ¨¡å—
            if platform == "tensorflow":
                tf = backend.tf
                optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
                target_state = create_target_state("tensorflow")
                params = initialize_parameters("tensorflow")
                
                circuit = create_variational_circuit(2, params)
                loss_history = []
                
                print(f"  å½“å‰åç«¯: {backend.name}")
                print(f"  TensorFlow ç‰ˆæœ¬: {tf.__version__}")
                print(f"  ç›®æ ‡çŠ¶æ€èŒƒæ•°: {tf.linalg.norm(target_state).numpy():.6f}")
                print(f"  åˆå§‹å‚æ•°: {params.numpy()}")
                
                for epoch in range(nepochs):
                    with tf.GradientTape() as tape:
                        circuit.set_parameters(params)
                        final_state = circuit().state()
                        loss = infidelity(final_state, target_state, backend=backend)
                    
                    grads = tape.gradient(loss, params)
                    optimizer.apply_gradients(zip([grads], [params]))
                    loss_history.append(loss.numpy())
                    
                    if (epoch + 1) % 200 == 0:
                        print(f"    Epoch {epoch+1:4d}: Loss = {loss.numpy():.6f}")
                
                # è®¡ç®—æœ€ç»ˆç»“æœ
                final_loss = loss_history[-1]
                final_fidelity = 1 - final_loss
                final_state = circuit().state()
                probabilities = np.abs(final_state.numpy())**2
                
                print(f"  âœ“ è®­ç»ƒå®Œæˆï¼")
                print(f"    æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
                print(f"    æœ€ç»ˆä¿çœŸåº¦: {final_fidelity:.6f}")
                print(f"    æœ€ç»ˆå‚æ•°: {params.numpy()}")
                print(f"    æ¦‚ç‡åˆ†å¸ƒ: {probabilities}")
                
                return {
                    'loss_history': [float(l) for l in loss_history],
                    'final_params': params.numpy().tolist(),
                    'final_loss': float(final_loss),
                    'final_fidelity': float(final_fidelity),
                    'probabilities': probabilities.tolist()
                }
                
            elif platform == "pytorch":
                import torch
                from qibo.quantum_info.metrics import infidelity
                
                optimizer = torch.optim.Adam
                target_state = create_target_state("pytorch")
                params = initialize_parameters("pytorch")
                optimizer = optimizer([params], lr=learning_rate)
                
                circuit = create_variational_circuit(2, params)
                loss_history = []
                
                print(f"  å½“å‰åç«¯: qiboml (pytorch)")
                print(f"  PyTorch ç‰ˆæœ¬: {torch.__version__}")
                print(f"  ç›®æ ‡çŠ¶æ€èŒƒæ•°: {torch.norm(target_state).item():.6f}")
                print(f"  åˆå§‹å‚æ•°: {params.detach().numpy()}")
                
                for epoch in range(nepochs):
                    optimizer.zero_grad()
                    
                    circuit.set_parameters(params)
                    final_state = circuit().state()
                    loss = infidelity(final_state, target_state)
                    
                    loss.backward()
                    optimizer.step()
                    
                    loss_history.append(loss.item())
                    
                    if (epoch + 1) % 200 == 0:
                        print(f"    Epoch {epoch+1:4d}: Loss = {loss.item():.6f}")
                
                # è®¡ç®—æœ€ç»ˆç»“æœ
                final_loss = loss_history[-1]
                final_fidelity = 1 - final_loss
                final_state = circuit().state()
                probabilities = np.abs(final_state.detach().numpy())**2
                
                print(f"  âœ“ è®­ç»ƒå®Œæˆï¼")
                print(f"    æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
                print(f"    æœ€ç»ˆä¿çœŸåº¦: {final_fidelity:.6f}")
                print(f"    æœ€ç»ˆå‚æ•°: {params.detach().numpy()}")
                print(f"    æ¦‚ç‡åˆ†å¸ƒ: {probabilities}")
                
                return {
                    'loss_history': [float(l) for l in loss_history],
                    'final_params': params.detach().numpy().tolist(),
                    'final_loss': float(final_loss),
                    'final_fidelity': float(final_fidelity),
                    'probabilities': probabilities.tolist()
                }
                
    except Exception as e:
        print(f"  âŒ {platform} è®­ç»ƒå¤±è´¥: {e}")
        return None

def plot_results(results, platform, output_dir="results"):
    """ç»˜åˆ¶ç»“æœçš„å®‰å…¨å‡½æ•°"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        plt.figure(figsize=(12, 4))
        
        # æŸå¤±å‡½æ•°
        plt.subplot(1, 3, 1)
        color = 'blue' if platform == 'tensorflow' else 'orange'
        plt.plot(results['loss_history'], color=color)
        plt.title(f'{platform.capitalize()}: æŸå¤±å‡½æ•°å˜åŒ–')
        plt.xlabel('è®­ç»ƒè½®æ¬¡')
        plt.ylabel('æŸå¤±å€¼')
        plt.yscale('log')
        plt.grid(True)
        
        # å‚æ•°å˜åŒ–
        plt.subplot(1, 3, 2)
        plt.bar(['Î¸â‚€ (RX)', 'Î¸â‚ (RY)'], results['final_params'], color=color)
        plt.title(f'{platform.capitalize()}: æœ€ç»ˆå‚æ•°')
        plt.ylabel('å‚æ•°å€¼ (å¼§åº¦)')
        
        # æ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(1, 3, 3)
        states = ['|00âŸ©', '|01âŸ©', '|10âŸ©', '|11âŸ©']
        plt.bar(states, results['probabilities'], color=color)
        plt.title(f'{platform.capitalize()}: æ¦‚ç‡åˆ†å¸ƒ')
        plt.ylabel('æ¦‚ç‡')
        plt.ylim(0, 1)
        
        plt.tight_layout()
        
        # å®‰å…¨ä¿å­˜æ–‡ä»¶
        output_path = os.path.join(output_dir, f'{platform}_results.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"    ğŸ“Š {platform.capitalize()} ç»“æœå›¾å·²ä¿å­˜ä¸º {output_path}")
        plt.close()
        
    except Exception as e:
        print(f"    âš  ç»˜å›¾å¤±è´¥: {e}")

def performance_comparison():
    """ä¿®å¤åçš„æ€§èƒ½å¯¹æ¯”å‡½æ•°"""
    try:
        print("  è¿›è¡Œæ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
        
        def measure_tensorflow_time(n_epochs=100):
            with backend_context("qiboml", "tensorflow") as backend:
                tf = backend.tf
                
                params = tf.Variable(tf.random.uniform((2,), dtype=tf.float64))
                optimizer = tf.keras.optimizers.Adam()
                target_state = tf.ones(4, dtype=tf.complex128) / 2.0
                circuit = Circuit(2)
                circuit.add(gates.RX(0, params[0]))
                circuit.add(gates.RY(1, params[1]))
                
                start_time = time.time()
                for _ in range(n_epochs):
                    with tf.GradientTape() as tape:
                        circuit.set_parameters(params)
                        final_state = circuit().state()
                        loss = infidelity(final_state, target_state, backend=backend)
                    grads = tape.gradient(loss, params)
                    optimizer.apply_gradients(zip([grads], [params]))
                
                return time.time() - start_time
        
        def measure_pytorch_time(n_epochs=100):
            with backend_context("qiboml", "pytorch"):
                import torch
                from qibo.quantum_info.metrics import infidelity
                
                params = torch.rand(2, dtype=torch.float64, requires_grad=True)
                optimizer = torch.optim.Adam([params])
                target_state = torch.ones(4, dtype=torch.complex128) / 2.0
                circuit = Circuit(2)
                circuit.add(gates.RX(0, params[0]))
                circuit.add(gates.RY(1, params[1]))
                
                start_time = time.time()
                for _ in range(n_epochs):
                    optimizer.zero_grad()
                    circuit.set_parameters(params)
                    final_state = circuit().state()
                    loss = infidelity(final_state, target_state)
                    loss.backward()
                    optimizer.step()
                
                return time.time() - start_time
        
        # æµ‹é‡æ—¶é—´
        tf_time = measure_tensorflow_time(100)
        torch_time = measure_pytorch_time(100)
        
        print(f"    TensorFlow è®­ç»ƒæ—¶é—´ (100è½®): {tf_time:.4f} ç§’")
        print(f"    PyTorch è®­ç»ƒæ—¶é—´ (100è½®): {torch_time:.4f} ç§’")
        print(f"    é€Ÿåº¦æ¯” (TF/PyTorch): {tf_time/torch_time:.2f}")
        
    except Exception as e:
        print(f"  âŒ æ€§èƒ½å¯¹æ¯”å¤±è´¥: {e}")

def main():
    print("=" * 60)
    print("ä½¿ç”¨ Qibo è‡ªåŠ¨å¾®åˆ†åç«¯è¿›è¡Œ VQA ç®—æ³•æ¼”ç¤ºï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        from qibo import Circuit, gates, set_backend
        from qibo.quantum_info import infidelity
        import qibo
        print("âœ“ Qibo å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·å®‰è£… qibo: pip install qibo qiboml")
        return
    
    # æ£€æŸ¥æ·±åº¦å­¦ä¹ æ¡†æ¶
    tensorflow_available = False
    pytorch_available = False
    
    try:
        import tensorflow as tf
        tensorflow_available = True
        print("âœ“ TensorFlow å¯ç”¨")
    except ImportError:
        print("âš  TensorFlow ä¸å¯ç”¨")
    
    try:
        import torch
        pytorch_available = True
        print("âœ“ PyTorch å¯ç”¨")
    except ImportError:
        print("âš  PyTorch ä¸å¯ç”¨")
    
    if not tensorflow_available and not pytorch_available:
        print("âŒ éœ€è¦è‡³å°‘å®‰è£… TensorFlow æˆ– PyTorch")
        return
    
    print("\n" + "=" * 60)
    print("å¼€å§‹ VQA ç®—æ³•æ¼”ç¤º")
    print("=" * 60)
    
    # å­˜å‚¨ç»“æœç”¨äºå¯èƒ½çš„åç»­åˆ†æ
    results = {}
    
    # è¿è¡Œæ¼”ç¤º
    if tensorflow_available:
        print("\nğŸ”¹ TensorFlow åç«¯æ¼”ç¤º")
        tf_results = train_vqa("qiboml", "tensorflow")
        if tf_results:
            results['tensorflow'] = tf_results
            plot_results(tf_results, 'tensorflow')
    
    if pytorch_available:
        print("\nğŸ”¹ PyTorch åç«¯æ¼”ç¤º")
        pytorch_results = train_vqa("qiboml", "pytorch")
        if pytorch_results:
            results['pytorch'] = pytorch_results
            plot_results(pytorch_results, 'pytorch')
    
    if tensorflow_available and pytorch_available:
        print("\nğŸ”¹ æ€§èƒ½å¯¹æ¯”")
        performance_comparison()
    
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    main()
```

## ä¸»è¦ä¿®å¤å†…å®¹

### 1. å¯¼å…¥ä¿®å¤
- ç»Ÿä¸€äº†æ‰€æœ‰å¯¼å…¥è¯­å¥
- ç¡®ä¿äº† `qibo` æ¨¡å—çš„æ­£ç¡®å¯¼å…¥
- æ·»åŠ äº†å¿…è¦çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨å¯¼å…¥

### 2. åç«¯ç®¡ç†ä¿®å¤
- æ·»åŠ äº† `backend_context` ä¸Šä¸‹æ–‡ç®¡ç†å™¨
- ç¡®ä¿åç«¯åˆ‡æ¢åèƒ½å¤Ÿæ¢å¤åŸå§‹çŠ¶æ€
- é˜²æ­¢å…¨å±€çŠ¶æ€æ±¡æŸ“

### 3. æ ‡å‡†åŒ–å‡½æ•°
- `create_variational_circuit`: æ ‡å‡†åŒ–ç”µè·¯åˆ›å»º
- `create_target_state`: æ ‡å‡†åŒ–ç›®æ ‡çŠ¶æ€åˆ›å»º
- `initialize_parameters`: æ ‡å‡†åŒ–å‚æ•°åˆå§‹åŒ–

### 4. è®­ç»ƒå‡½æ•°é‡æ„
- å°† TensorFlow å’Œ PyTorch è®­ç»ƒé€»è¾‘åˆå¹¶åˆ° `train_vqa` å‡½æ•°
- ç»Ÿä¸€äº†é”™è¯¯å¤„ç†å’Œç»“æœè¿”å›æ ¼å¼
- æ”¹è¿›äº†å‚æ•°éªŒè¯å’ŒçŠ¶æ€æ£€æŸ¥

### 5. å¯è§†åŒ–ä¿®å¤
- åˆ›å»ºäº†ç»Ÿä¸€çš„ `plot_results` å‡½æ•°
- æ·»åŠ äº†è¾“å‡ºç›®å½•åˆ›å»ºå’Œæƒé™æ£€æŸ¥
- æ”¹è¿›äº†é”™è¯¯å¤„ç†

### 6. æ€§èƒ½æ¯”è¾ƒä¿®å¤
- ä¿®å¤äº†åç«¯è®¾ç½®å‚æ•°é¡ºåºé—®é¢˜
- ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿åç«¯çŠ¶æ€æ­£ç¡®æ¢å¤
- æ”¹è¿›äº†é”™è¯¯å¤„ç†

## ä½¿ç”¨æ–¹æ³•

1. ç¡®ä¿å®‰è£…äº†å¿…è¦çš„ä¾èµ–ï¼š
```bash
pip install qibo qiboml tensorflow torch matplotlib
```

2. è¿è¡Œä¿®å¤åçš„è„šæœ¬ï¼š
```bash
python vqa_demo_fixed.py
```

3. ç»“æœå°†ä¿å­˜åœ¨ `results/` ç›®å½•ä¸­

è¿™ä¸ªä¿®å¤ç‰ˆæœ¬ç¡®ä¿äº†åŠŸèƒ½çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ï¼Œè§£å†³äº†åŸä»£ç ä¸­çš„æ‰€æœ‰å…³é”®é—®é¢˜ã€‚